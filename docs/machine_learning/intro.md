# Machine Learning Interview Questions

This page compiles common machine learning interview questions â€” covering theory, coding, and system design â€” to help you prepare for MLE/ML scientist roles.

---

## ğŸ“˜ Categories

- [Theory & Concepts](#theory--concepts)
- [Algorithms & Models](#algorithms--models)
- [Evaluation & Metrics](#evaluation--metrics)
- [Coding & Implementation](#coding--implementation)
- [System Design for ML](#system-design-for-ml)
- [Behavioral & Applied ML](#behavioral--applied-ml)

---

## ğŸ§  Theory & Concepts

> Expect questions that test your understanding of statistical and ML foundations.

- What is the bias-variance tradeoff?
- Explain overfitting vs underfitting.
- What is the curse of dimensionality?
- Describe the difference between generative and discriminative models.
- How does regularization (L1 vs L2) work?

---

## ğŸ” Algorithms & Models

> You may be asked to compare or explain core ML models and their use cases.

- How does logistic regression work?
- Whatâ€™s the difference between decision trees and random forests?
- How does a support vector machine find the decision boundary?
- What are the assumptions behind linear regression?
- Compare bagging vs boosting.

---

## ğŸ“ Evaluation & Metrics

> Be ready to justify model performance and metric choices.

- Whatâ€™s the difference between precision and recall?
- When would you use F1 score instead of accuracy?
- What is AUC-ROC and when is it useful?
- How do you perform cross-validation?
- What is a confusion matrix?

---

## ğŸ’» Coding & Implementation

> Expect LeetCode-style + ML pipeline-style questions.

- Implement logistic regression from scratch.
- Write code to split a dataset into train/validation/test.
- Normalize a dataset using Min-Max and Z-score methods.
- How would you vectorize a text dataset using TF-IDF?
- Implement K-Means clustering from scratch.

---

## ğŸ—ï¸ System Design for ML

> These test your ability to deploy and scale ML systems.

- How would you design a real-time recommendation engine?
- How do you monitor data drift in production?
- Design a system that continuously retrains an ML model on new data.
- How would you serve a model with latency constraints?
- Batch vs real-time inference tradeoffs?

---

## ğŸ§ª Behavioral & Applied ML

> These focus on your project experience and product mindset.

- Tell me about an ML project you led end-to-end.
- How did you decide which features to include?
- Have you ever encountered label leakage?
- How did you handle imbalanced data?
- What tradeoffs did you make in model complexity vs interpretability?

---

## ğŸ“š Resources

- [Machine Learning Mastery](https://machinelearningmastery.com/)
- [ML Interview Book by Chip Huyen](https://huyenchip.com/ml-interviews-book/)
- [FastAI Interview Guide](https://course.fast.ai/)

---

## ğŸ“ Tips

- Tie answers to real projects you've worked on
- Always clarify assumptions and constraints
- Use diagrams and examples when explaining systems
- Know how to reason through **why** a model performs poorly â€” not just what to tune
